# -*- coding: utf-8 -*-
"""Conheça o Colab

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/notebooks/intro.ipynb
"""

!pip install deepface

from deepface import DeepFace

from PIL import Image

from IPython.display import display, Javascript
from google.colab.output import eval_js
from base64 import b64decode

def take_photo(filename='suafoto.jpg', quality=0.8):
  js = Javascript('''
    async function takePhoto(quality) {
      const div = document.createElement('div');
      const capture = document.createElement('button');
      capture.textContent = 'Capture';
      div.appendChild(capture);

      const video = document.createElement('video');
      video.style.display = 'block';
      const stream = await navigator.mediaDevices.getUserMedia({video: true});

      document.body.appendChild(div);
      div.appendChild(video);
      video.srcObject = stream;
      await video.play();

      // Resize the output to fit the video element.
      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);

      // Wait for Capture to be clicked.
      await new Promise((resolve) => capture.onclick = resolve);

      const canvas = document.createElement('canvas');
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      canvas.getContext('2d').drawImage(video, 0, 0);
      stream.getVideoTracks()[0].stop();
      div.remove();
      return canvas.toDataURL('image/jpg', quality);
    }
    ''')
  display(js)
  data = eval_js('takePhoto({})'.format(quality))
  binary = b64decode(data.split(',')[1])
  with open(filename, 'wb') as f:
    f.write(binary)

 # Convert the image to RGB mode
  img = Image.open(filename).convert('RGB')
  img.save(filename)
  return filename

take_photo()

emb = DeepFace.represent(img_path = "suafoto.jpg", model_name = 'Facenet')

len(emb)

emb[0]

len(emb[0]['embedding'])

faces = DeepFace.extract_faces(img_path = "suafoto.jpg")

from PIL import Image
img = Image.open("suafoto.jpg")  # Load the original image
faces_list = []
for face in faces:
    x, y, w, h = face['facial_area']['x'], face['facial_area']['y'], face['facial_area']['w'], face['facial_area']['h']
    face_patch = img.crop((x, y, x + w, y + h))
    faces_list.append(face_patch)

len(faces_list)

faces_list[0]

faces_list[1]

faces_list[0].save("face1.jpg")

len(emb[0]['embedding'])

!pip install requests

import requests

emb = DeepFace.represent(img_path = "face1.jpg", model_name = 'Facenet')

vetor = emb[0]['embedding']
nome_id = "pessoa_face1"

#não alterei a url pois não fui capaz de obter uma
api_url = "https://localhost:8000/buscar?lat=40&lon=40"

payload = {"embedding": vetor,
           "id": nome_id
}
response = requests.post(api_url, json = payload) # Use json= for sending JSON data

if response.status_code == 200:
    print("Success!")
else:
    print("Error:", response.status_code)